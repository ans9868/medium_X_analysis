{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9660e951-3ff0-41c3-bbcb-fe64e22b7886",
   "metadata": {},
   "source": [
    "# Quick Introduction:\n",
    "Hello, this is a jupyter notebook created by Adel for the medium article {article title}. The goal of the code is to analyze the culture of a goegraphical region according to how people associated with said region tweet online. I recomend reading the article for more information. \n",
    "\n",
    "#### **The official summary is at the bottom of this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f9891-96fe-4b67-a12b-602fd0afd8c5",
   "metadata": {},
   "source": [
    "# Step 0: Sanity Checks\n",
    "Here we make sure everything loads and works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "044143b2-6a6a-48df-9462-7378e0cd89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package load \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import random\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff6d66b0-6a0c-4b9c-a249-4f6c489633c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded successfully from .env\n"
     ]
    }
   ],
   "source": [
    "# This loads variables from .env into environment variables\n",
    "load_dotenv()\n",
    "\n",
    "BEARER_TOKEN = os.getenv(\"X_BEARER_TOKEN\")\n",
    "if BEARER_TOKEN is not None:\n",
    "    print(\"Token loaded successfully from .env\")\n",
    "else:\n",
    "    print(\"Token not found in .env, refer to .env.example\")\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
    "BASE_URL = \"https://api.x.com/2\"\n",
    "\n",
    "    \n",
    "# maybe test token works by seeing if elon's user can be pinged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcb3ef-df96-45fa-bd44-2aa4334837c9",
   "metadata": {},
   "source": [
    "# Step 1: Finding X users to Scrape and scraping their sweet sweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5fd06c-b1df-4086-9908-df5930dfc72a",
   "metadata": {},
   "source": [
    "## step 1.1: Load the config for our target area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ade6397b-8d7c-45ea-af1a-6190635ec943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config for uk:\n",
      "{\n",
      "  \"region_name\": \"uk\",\n",
      "  \"local_seeds\": \"../data/local_seeds/uk.json\",\n",
      "  \"users_output\": \"../data/users/uk_users.jsonl\",\n",
      "  \"users_adjacent_output\": \"../data/users_adjacent/uk_users.jsonl\",\n",
      "  \"tweets_output\": \"../data/tweets/uk_tweets.jsonl\",\n",
      "  \"bio_keywords\": [\n",
      "    \"uk\",\n",
      "    \"united kingdom\",\n",
      "    \"england\",\n",
      "    \"scotland\",\n",
      "    \"wales\",\n",
      "    \"...\"\n",
      "  ],\n",
      "  \"max_mentions_per_seed\": 1,\n",
      "  \"max_tweets_per_user\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# select target, default available is \"uk\", \"nyc\", \"singapore\"\n",
    "target_area = \"uk\"\n",
    "\n",
    "# Notice ! If you want to have more seeds then use uk_extended ... the standard uk.json is small and for testing\n",
    "CONFIG_PATH = Path(\"..\") / \"configs\" / f\"{target_area}.json\"\n",
    "\n",
    "with open (CONFIG_PATH) as f:\n",
    "    CFG = json.load(f)\n",
    "\n",
    "print(f\"Loaded config for {target_area}:\")\n",
    "cfg_copy = CFG.copy()\n",
    "if len(CFG['bio_keywords']) > 5:\n",
    "    cfg_copy['bio_keywords'] = CFG['bio_keywords'][:5] + ['...']\n",
    "print(json.dumps(cfg_copy, indent=2))\n",
    "del cfg_copy # only used for example print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "537eab0c-be8b-4e53-8268-47a97d891ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uk seed types are: sports, music, tech_lifestyle, comedy\n",
      "\n",
      "First few sports seeds:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@premierleague', '@Arsenal']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(CFG[\"local_seeds\"]) as f:\n",
    "    seeds = json.load(f)\n",
    "\n",
    "seed_types = list(seeds.keys())\n",
    "print(f\"{target_area} seed types are:\", \", \".join(seed_types))\n",
    "\n",
    "# Peek at the first few in one category, e.g. sports\n",
    "print(\"\\nFirst few sports seeds:\")\n",
    "seeds[\"sports\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69522d-5c67-4ba3-be47-4f10638265f2",
   "metadata": {},
   "source": [
    "## Step 1.2: Clean + Validate seed handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a470389-0864-4755-a57e-92c0fccbb224",
   "metadata": {},
   "source": [
    "### step 1.2.1 Filter for valid seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a90bfc26-3808-4d55-9b7e-62286c427a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid uk seeds: 8 | Invalid: 0\n"
     ]
    }
   ],
   "source": [
    "def is_valid_username(u: str) -> bool:\n",
    "    return bool(re.fullmatch(r\"[A-Za-z0-9_]{1,15}\", u))\n",
    "\n",
    "seed_types = list(seeds.keys())\n",
    "\n",
    "valid_seeds = []\n",
    "invalid_seeds = []\n",
    "\n",
    "for seed_types in seeds:\n",
    "    for seed in seeds[seed_types]:\n",
    "        clean = seed.lstrip(\"@\") if seed.startswith(\"@\") else seed\n",
    "        if is_valid_username(clean):\n",
    "            valid_seeds.append(clean)\n",
    "        else:\n",
    "            invalid_seeds.append(seed)\n",
    "\n",
    "print(f\"Valid {target_area} seeds: {len(valid_seeds)} | Invalid: {len(invalid_seeds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a0ec8-cba3-4afa-b860-933e75eb6d25",
   "metadata": {},
   "source": [
    "### step 1.2.2: Resolve seeds via `/2/users/by` (X API v2)\n",
    "API level validation: \"do these usernames actually exist, lets get their metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa12d60f-bc81-4ad0-a8a9-38f96ed984f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_usernames(usernames: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    X API v2: Lookup users by username.\n",
    "\n",
    "    HTTP:\n",
    "        GET /2/users/by\n",
    "\n",
    "    Docs:\n",
    "        https://developer.x.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by\n",
    "\n",
    "    Args:\n",
    "        usernames:\n",
    "            List of X usernames (without the leading '@') to look up.\n",
    "\n",
    "    Returns:\n",
    "        A list of user objects returned in the 'data' field of the response,\n",
    "        each including fields like id, username, name, location, description,\n",
    "        and public_metrics (depending on user.fields requested).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i in range(0, len(usernames), 100):\n",
    "        batch = usernames[i:i+100]\n",
    "        params = {\n",
    "            \"usernames\": \",\".join(batch),\n",
    "            \"user.fields\": \"id,username,name,location,description,public_metrics\"\n",
    "        }\n",
    "        try:\n",
    "            r = requests.get(f\"{BASE_URL}/users/by\", headers=HEADERS, params=params)\n",
    "            r.raise_for_status()\n",
    "            data = r.json().get(\"data\", [])\n",
    "            results.extend(data)\n",
    "            print(f\"Batch {i//100}: {len(data)}/{len(batch)} users\")\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"Batch {i//100} error: {e}\")\n",
    "        time.sleep(0.5)  # to avoid have timeouts & ensure expected behavior\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7303ab37-40a6-4ff8-8e02-58167335f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: 8/8 users\n",
      "Resolved 8 seed user objects out of 8 valid usernames\n"
     ]
    }
   ],
   "source": [
    "seed_users = lookup_usernames(valid_seeds)\n",
    "print(f\"Resolved {len(seed_users)} seed user objects out of {len(valid_seeds)} valid usernames\")\n",
    "# TODO: Should we save seeds ... maybe seeds_unfiltered and seeds_filtered directories respectfully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fc860-e576-4713-aa77-5bd0ae851f2e",
   "metadata": {},
   "source": [
    "## Step 1.3: Find Adjacent Accounts to Seeds + Filter for Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48020afe-1d4c-42f0-8b00-810255d2c77d",
   "metadata": {},
   "source": [
    "### step 1.3.1: Find adjacent Accounts to seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d072535c-48d3-4cd8-9a57-813473d32f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the PDF – this stays as \"find adjacent users by mentions\"\n",
    "def search_region_mentions_batched(\n",
    "    seeds: List[Dict],\n",
    "    batch_size: int = 20,\n",
    "    max_adj: int = 3000,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    X API v2: Find 'adjacent' users who mention the seed accounts.\n",
    "\n",
    "    HTTP:\n",
    "        GET /2/tweets/search/recent\n",
    "\n",
    "    Docs:\n",
    "        https://developer.x.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "\n",
    "    Query pattern (for UK example):\n",
    "        \"UK (@premierleague OR @Arsenal OR @ChelseaFC ...)\"\n",
    "\n",
    "    Args:\n",
    "        seeds:\n",
    "            List of user objects (each with at least a 'username' key) used as local seeds.\n",
    "        batch_size:\n",
    "            How many seed usernames to include in each search query batch.\n",
    "        max_adj:\n",
    "            Maximum number of unique adjacent users to collect before stopping.\n",
    "\n",
    "    Returns:\n",
    "        A list of unique user objects from the 'includes.users' field of search results.\n",
    "    \"\"\"\n",
    "    # usernames of your seed accounts\n",
    "    usernames = [u[\"username\"] for u in seeds]\n",
    "\n",
    "    # Ssimple base region term. You could later make this more complex\n",
    "    region_term = CFG.get(\"tweet_region_term\", CFG[\"region_name\"])  # e.g. \"UK\"\n",
    "\n",
    "    all_adjacent: Dict[str, Dict] = {}\n",
    "    total_fetched = 0\n",
    "\n",
    "    for i in range(0, len(usernames), batch_size):\n",
    "        batch = usernames[i:i + batch_size]\n",
    "        batch_handles = [f\"@{u}\" for u in batch]\n",
    "        query = f'{region_term} ({\" OR \".join(batch_handles)})'\n",
    "\n",
    "        print(f\"Batch {i//batch_size + 1}: {len(batch)} seeds → {query[:120]}...\")\n",
    "\n",
    "        url = f\"{BASE_URL}/tweets/search/recent\"\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"max_results\": 100, # Note: here we don't do the min of max_adj - total_fetched because not guaranteed unique and so by dong 100 can reduce total # of HTTP calls\n",
    "            \"tweet.fields\": \"author_id\", # --> the account id of who posted the tweet\n",
    "            \"expansions\": \"author_id\",\n",
    "            \"user.fields\": \"id,username,name,location,description,public_metrics\", #location is a parameter inputed by the user, not like 'geo' coordinates like in the old twitter API\n",
    "        }\n",
    "\n",
    "        fetched_in_batch = 0\n",
    "\n",
    "        while fetched_in_batch < 500 and total_fetched < max_adj:\n",
    "            try:\n",
    "                r = requests.get(url, headers=HEADERS, params=params)\n",
    "                r.raise_for_status()\n",
    "                resp = r.json()\n",
    "\n",
    "                # users come back in the 'includes.users' block\n",
    "                includes = resp.get(\"includes\", {}).get(\"users\", [])\n",
    "                for user in includes:\n",
    "                    uid = user[\"id\"]\n",
    "                    if uid not in all_adjacent:\n",
    "                        all_adjacent[uid] = user\n",
    "                        total_fetched += 1\n",
    "                        fetched_in_batch += 1\n",
    "\n",
    "                token = resp.get(\"meta\", {}).get(\"next_token\")\n",
    "                if not token:\n",
    "                    break\n",
    "\n",
    "                params[\"next_token\"] = token\n",
    "                time.sleep(0.5)  # avoid rate limits\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "                break\n",
    "\n",
    "        print(f\"  → {fetched_in_batch} new users (total: {total_fetched})\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        if total_fetched >= max_adj:\n",
    "            print(\"Reached max_adj limit, stopping.\")\n",
    "            break\n",
    "\n",
    "    return list(all_adjacent.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d49d74c-758c-46d9-8229-66e6ea70f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 8 seeds → uk (@premierleague OR @Arsenal OR @TheO2 OR @RoyalAlbertHall OR @techUK OR @LDNTechWeek OR @Tate OR @britishmuseum)...\n",
      "  → 212 new users (total: 212)\n",
      "Reached max_adj limit, stopping.\n",
      "Saved 212 adjacent users → ../data/users_adjacent/uk_adjacent_users.jsonl\n"
     ]
    }
   ],
   "source": [
    "adjacent_users = search_region_mentions_batched(\n",
    "    seed_users,\n",
    "    batch_size=20,\n",
    "    max_adj=CFG.get(\"max_adjacent_users\", 200),\n",
    ")\n",
    "# An idea to make it more robust could search+filter for accounts between a range of followers, a certain number of tweets account age ect.\n",
    "\n",
    "adj_dir = Path(\"../data/users_adjacent\")\n",
    "adj_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "adj_path = adj_dir / f\"{target_area}_adjacent_users.jsonl\"\n",
    "with adj_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for u in adjacent_users:\n",
    "        f.write(json.dumps(u) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(adjacent_users)} adjacent users → {adj_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645f05a-46d2-4657-8d51-854f12694adc",
   "metadata": {},
   "source": [
    "### 1.3.2: Filter Adjacent Users by bio (confirmed locals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4beadc28-2dba-4b07-8d7e-247e210db321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacent users: 212 | confirmed locals: 121\n",
      "Saved 121 confirmed local users → ../data/users/uk_users.jsonl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Optional: Load from file\n",
    "adj_path = Path(\"../data/users_adjacent\") / f\"{target_area}_adjacent_users.jsonl\"\n",
    "with adj_path.open() as f:\n",
    "     adj_rows = [json.loads(line) for line in f]\n",
    "\n",
    "adj_df = pd.DataFrame(adj_rows)\n",
    "\"\"\"\n",
    "\n",
    "adj_df = pd.DataFrame(adjacent_users)\n",
    "\n",
    "# Combine description + location into a single \"bio-like\" field\n",
    "adj_df[\"bio\"] = (\n",
    "    adj_df[\"description\"].fillna(\"\") + \" \" +\n",
    "    adj_df[\"location\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "adj_df[\"is_in_region\"] = adj_df[\"bio\"].apply(bio_matches_region)\n",
    "\n",
    "region_users_df = adj_df[adj_df[\"is_in_region\"]].copy()\n",
    "print(\"Adjacent users:\", len(adj_df), \"| confirmed locals:\", len(region_users_df))\n",
    "\n",
    "# Save to the final users_output path from config\n",
    "final_path = Path(CFG[\"users_output\"])\n",
    "final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "region_users_df.to_json(final_path, orient=\"records\", lines=True)\n",
    "\n",
    "print(f\"Saved {len(region_users_df)} confirmed local users → {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e3917-cf7f-4ee0-a339-b3134d1594c7",
   "metadata": {},
   "source": [
    "# 1.4: Get tweets of confirmed local users\n",
    "### We will pick some of the locals and get their tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1afa342-71cb-4986-97fc-f0ec4e660488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tweets(user_id: str, max_tweets: int = 50) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    X API v2: Get recent Tweets by user ID.\n",
    "\n",
    "    HTTP:\n",
    "        GET /2/users/:id/tweets\n",
    "\n",
    "    Docs:\n",
    "        https://developer.x.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
    "\n",
    "    Description:\n",
    "        Fetches up to `max_tweets` recent Tweets for a single user.\n",
    "        Requests are paginated with `max_results=100`\n",
    "        per API call and use `next_token` from the response `meta` object to\n",
    "        continue until either `max_tweets` is reached or there are no more\n",
    "        Tweets available.\n",
    "\n",
    "        Retweets and replies are excluded so that the resulting dataset reflects\n",
    "        more of the user's own original content.\n",
    "\n",
    "    Args:\n",
    "        user_id:\n",
    "            The numeric user ID (as a string) of the account whose Tweets\n",
    "            should be fetched.\n",
    "        max_tweets:\n",
    "            Maximum number of Tweets to return for this user. The function may\n",
    "            return fewer if the user has fewer original Tweets or if the API\n",
    "            stops returning pages.\n",
    "\n",
    "    Returns:\n",
    "        A list of Tweet objects (dicts) as returned in the response `data`\n",
    "        field. Each Tweet includes at least:\n",
    "            - id\n",
    "            - author_id\n",
    "            - text\n",
    "            - created_at\n",
    "            - lang\n",
    "            - public_metrics\n",
    "        The list length is at most `max_tweets`.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/users/{user_id}/tweets\"\n",
    "    params = {\n",
    "        \"max_results\": min(max_tweets, 100),  # API page size, we'll stop at max_tweets\n",
    "        \"tweet.fields\": \"id,author_id,text,created_at,lang,public_metrics\",\n",
    "        \"exclude\": \"retweets,replies\",\n",
    "    }\n",
    "\n",
    "    tweets: List[Dict] = []\n",
    "\n",
    "    while len(tweets) < max_tweets:\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params)\n",
    "            r.raise_for_status()\n",
    "            resp = r.json()\n",
    "            data = resp.get(\"data\", [])\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            tweets.extend(data)\n",
    "\n",
    "            token = resp.get(\"meta\", {}).get(\"next_token\")\n",
    "            if not token:\n",
    "                break\n",
    "\n",
    "            params[\"next_token\"] = token\n",
    "            time.sleep(1)  # be nice to the API\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching tweets for user {user_id}: {e}\")\n",
    "            break\n",
    "\n",
    "    # guarantee we don't exceed max_tweets\n",
    "    return tweets[:max_tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "101a4122-ce88-4907-bb08-cd15c8e36233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " ['1264821227610419201',\n",
       "  '1062024201660493824',\n",
       "  '908358114675707906',\n",
       "  '1040550277131186176',\n",
       "  '1064229456'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Load from file \n",
    "# locals_path = Path(CFG[\"users_output\"])\n",
    "# with locals_path.open() as f:\n",
    "#     locals_list = [json.loads(line) for line in f]\n",
    "# locals_df = pd.DataFrame(locals_list)\n",
    "\n",
    "\n",
    "# Here we pick 100 locals \n",
    "num_random_locals = CFG.get(\"num_random_locals\", 100)\n",
    "locals_df = region_users_df.copy()\n",
    "\n",
    "random.seed(42)\n",
    "n_locals = min(num_random_locals, len(locals_df))\n",
    "sampled_locals_df = locals_df.sample(n=n_locals, random_state=42)\n",
    "\n",
    "# user IDs to query\n",
    "local_ids = sampled_locals_df[\"id\"].astype(str).tolist()\n",
    "len(local_ids), local_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab2fd740-14ff-455b-ab1e-3a9c75fb8cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  44%|███████         | 44/100 [01:13<02:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 519767002: 402 Client Error: Payment Required for url: https://api.x.com/2/users/519767002/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  45%|███████▏        | 45/100 [01:14<01:40,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 310201041: 402 Client Error: Payment Required for url: https://api.x.com/2/users/310201041/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  46%|███████▎        | 46/100 [01:15<01:27,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 248768462: 402 Client Error: Payment Required for url: https://api.x.com/2/users/248768462/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  47%|███████▌        | 47/100 [01:16<01:17,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 3339230698: 402 Client Error: Payment Required for url: https://api.x.com/2/users/3339230698/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  48%|███████▋        | 48/100 [01:17<01:10,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 2217786008: 402 Client Error: Payment Required for url: https://api.x.com/2/users/2217786008/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  49%|███████▊        | 49/100 [01:18<01:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 72523656: 402 Client Error: Payment Required for url: https://api.x.com/2/users/72523656/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  50%|████████        | 50/100 [01:19<01:01,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 261628910: 402 Client Error: Payment Required for url: https://api.x.com/2/users/261628910/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  51%|████████▏       | 51/100 [01:20<00:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 3169753600: 402 Client Error: Payment Required for url: https://api.x.com/2/users/3169753600/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  52%|████████▎       | 52/100 [01:21<00:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 4526739273: 402 Client Error: Payment Required for url: https://api.x.com/2/users/4526739273/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  53%|████████▍       | 53/100 [01:23<00:54,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 1909905669438005248: 402 Client Error: Payment Required for url: https://api.x.com/2/users/1909905669438005248/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  54%|████████▋       | 54/100 [01:24<00:52,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 1620452334617624578: 402 Client Error: Payment Required for url: https://api.x.com/2/users/1620452334617624578/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  55%|████████▊       | 55/100 [01:25<00:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 1571695559328645123: 402 Client Error: Payment Required for url: https://api.x.com/2/users/1571695559328645123/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  56%|████████▉       | 56/100 [01:26<00:49,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 1479155367363944450: 402 Client Error: Payment Required for url: https://api.x.com/2/users/1479155367363944450/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  57%|█████████       | 57/100 [01:27<00:48,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 3662824157: 402 Client Error: Payment Required for url: https://api.x.com/2/users/3662824157/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  58%|█████████▎      | 58/100 [01:28<00:46,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 182785352: 402 Client Error: Payment Required for url: https://api.x.com/2/users/182785352/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  59%|█████████▍      | 59/100 [01:29<00:45,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 2669193350: 402 Client Error: Payment Required for url: https://api.x.com/2/users/2669193350/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  60%|█████████▌      | 60/100 [01:30<00:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 18448883: 402 Client Error: Payment Required for url: https://api.x.com/2/users/18448883/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  61%|█████████▊      | 61/100 [01:31<00:43,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 15653762: 402 Client Error: Payment Required for url: https://api.x.com/2/users/15653762/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  62%|█████████▉      | 62/100 [01:33<00:42,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 111570867: 402 Client Error: Payment Required for url: https://api.x.com/2/users/111570867/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  63%|██████████      | 63/100 [01:34<00:40,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 85434818: 402 Client Error: Payment Required for url: https://api.x.com/2/users/85434818/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  64%|██████████▏     | 64/100 [01:35<00:39,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 1399665283: 402 Client Error: Payment Required for url: https://api.x.com/2/users/1399665283/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  84%|█████████████▍  | 84/100 [02:08<00:27,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 2507994280: 402 Client Error: Payment Required for url: https://api.x.com/2/users/2507994280/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  85%|█████████████▌  | 85/100 [02:09<00:23,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 637063232: 402 Client Error: Payment Required for url: https://api.x.com/2/users/637063232/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  86%|█████████████▊  | 86/100 [02:10<00:19,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 568149499: 402 Client Error: Payment Required for url: https://api.x.com/2/users/568149499/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  87%|█████████████▉  | 87/100 [02:11<00:17,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 300909522: 402 Client Error: Payment Required for url: https://api.x.com/2/users/300909522/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  88%|██████████████  | 88/100 [02:12<00:15,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 36489575: 402 Client Error: Payment Required for url: https://api.x.com/2/users/36489575/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  89%|██████████████▏ | 89/100 [02:13<00:13,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 6120962: 402 Client Error: Payment Required for url: https://api.x.com/2/users/6120962/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  90%|██████████████▍ | 90/100 [02:14<00:11,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 727660210244993024: 402 Client Error: Payment Required for url: https://api.x.com/2/users/727660210244993024/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  91%|██████████████▌ | 91/100 [02:16<00:10,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 574059441: 402 Client Error: Payment Required for url: https://api.x.com/2/users/574059441/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals:  92%|██████████████▋ | 92/100 [02:17<00:09,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets for user 299219144: 402 Client Error: Payment Required for url: https://api.x.com/2/users/299219144/tweets?max_results=100&tweet.fields=id%2Cauthor_id%2Ctext%2Ccreated_at%2Clang%2Cpublic_metrics&exclude=retweets%2Creplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pulling tweets for uk locals: 100%|███████████████| 100/100 [02:30<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "max_per_user = CFG.get(\"max_tweets_per_user\", 1) # had to set it really low due to running out of credits\n",
    "\n",
    "all_tweets: List[Dict] = []\n",
    "\n",
    "for uid in tqdm(local_ids, desc=f\"Pulling tweets for {target_area} locals\"):\n",
    "    user_tweets = get_user_tweets(uid, max_tweets=max_per_user)\n",
    "\n",
    "    # Just in case, enforce author_id here too (should already be set by the API)\n",
    "    for t in user_tweets:\n",
    "        t.setdefault(\"author_id\", uid)\n",
    "\n",
    "    all_tweets.extend(user_tweets)\n",
    "    time.sleep(0.5)  # avoid hammering the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f68124f-da21-4d28-a494-dd4d9a861d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 64 tweets → ../data/tweets/uk_tweets.jsonl\n"
     ]
    }
   ],
   "source": [
    "tweets_path = Path(CFG[\"tweets_output\"])\n",
    "tweets_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with tweets_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for t in all_tweets:\n",
    "        f.write(json.dumps(t) + \"\\n\")\n",
    "\n",
    "print(f\"Collected {len(all_tweets)} tweets → {tweets_path}\")\n",
    "# ran out of credits during this test so I didn't get all of the tweets :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3bca5e3-53c0-4a8d-b2e1-336f99f2bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We finished getting our data, the data analysis section will be in x_api_culture_analysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"We finished getting our data, the data analysis section will be in x_api_culture_analysis.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cb198-de49-42e5-b501-1667bf0bd397",
   "metadata": {},
   "source": [
    "## Overall Summary of Step 1\n",
    "\n",
    "In this notebook, I used the X API v2 to build a small, end-to-end data pipeline for one region (the UK). Step 1 breaks down into four sub-steps:\n",
    "\n",
    "**Step 1.1 – Load region config**\n",
    "\n",
    "- Loaded the `uk` config from `../configs/uk.json`.\n",
    "- This defined the local seeds file, all output paths, the UK bio keywords, and control knobs like `max_mentions_per_seed`, `max_adjacent_users`, `num_random_locals`, and `max_tweets_per_user`.\n",
    "\n",
    "**Step 1.2 – Validate and resolve seed accounts**\n",
    "\n",
    "- Loaded the seed handles from `../data/local_seeds/uk.json`.\n",
    "- Cleaned them (stripped `@`, checked they were valid usernames).\n",
    "- Resolved them via `GET /2/users/by` to get full user objects for each seed (name, description, location, public metrics).\n",
    "\n",
    "**Step 1.3 – Find “adjacent” users via mentions**\n",
    "\n",
    "- Queried `GET /2/tweets/search/recent` for tweets that mention the seed accounts plus a UK term (e.g. `\"UK (@premierleague OR @Arsenal ...)\"`), in batches.\n",
    "- Collected the authors returned in `includes.users` as “adjacent users” and wrote them to  \n",
    "  `../data/users_adjacent/uk_adjacent_users.jsonl`.\n",
    "\n",
    "**Step 1.4 – Filter confirmed locals and pull their tweets**\n",
    "\n",
    "- Combined each adjacent user’s `description` and `location` into a simple “bio” string.\n",
    "- Kept only users whose bios contained at least one UK keyword (e.g. “uk”, “england”, “scotland”, “glasgow”, etc.), and wrote these confirmed locals to  \n",
    "  `../data/users/uk_users.jsonl`.\n",
    "- Randomly sampled up to `num_random_locals` confirmed locals.\n",
    "- For each sampled user, called `GET /2/users/:id/tweets` (excluding retweets and replies) and saved the results to  \n",
    "  `../data/tweets/uk_tweets.jsonl`.\n",
    "\n",
    "\n",
    "Because this was a live test run on my own X developer account, I hit the **402 Payment Required** errors part way through fetching tweets and ended up with a **partial UK tweets dataset** (64 tweets total). Across this and a couple of earlier test calls, I spent roughly **\\$20** in API usage.\n",
    "\n",
    "> **Important:**  \n",
    "> The data from *this specific run* (with partial UK tweets) will **not** be used in the main data-analysis section of the project. This notebook is meant to document **how** I collected the data and all the little gotchas of using X API v2 (rate limits, access tiers, cost, etc.).\n",
    "\n",
    "For the actual cultural analysis, I’ll be working in a separate notebook, **`x_api_culture_analysis.ipynb`**, where I load pre-collected datasets for multiple regions and:\n",
    "\n",
    "- compare **UK vs NYC** users on both the **dictionary-based features** and **embedding-based features**,  \n",
    "- run PCA/UMAP to visualize the “cultural space” of each city, and  \n",
    "- use those region-level profiles to design different chatbot personas.\n",
    "\n",
    "So you can think of this notebook as **“how I got the data and what it cost”**, and `x_api_culture_analysis` as **“what I actually did with that data once I had it.”**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb009df-58bc-442d-8656-53865c59d0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
